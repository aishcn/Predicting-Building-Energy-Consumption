{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reduced_df, \n",
    "                                                    df_t['site_eui'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('XGB', XGBRegressor()))\n",
    "    level0.append(('SVR', SVR()))\n",
    "    level0.append(('GBR', GradientBoostingRegressor()))\n",
    "    # level0.append(('CATB', CatBoostRegressor())),\n",
    "    level0.append(('ElNET', ElasticNet())),\n",
    "    level0.append(('LGBM', LGBMRegressor()))\n",
    "    # define meta learner model\n",
    "    level1 = LinearRegression()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingRegressor(estimators=level0, final_estimator=level1, cv=10)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg0 = ElasticNet(random_state=42)\n",
    "reg1 = XGBRegressor(random_state=42)\n",
    "reg2 = SVR()\n",
    "reg3 = GradientBoostingRegressor(random_state=42)\n",
    "#reg4 = CatBoostRegressor(random_state=42)\n",
    "reg5 = LGBMRegressor(random_state=42)\n",
    "#reg6 = get_stacking()\n",
    "\n",
    "# Initiaze the hyperparameters for each dictionary\n",
    "\n",
    "param0 = {}\n",
    "param0['regressor__max_iter'] = [1,5,10,20,50,100,200,500]\n",
    "param0['regressor__alpha'] = np.logspace(-5, 5, 100, endpoint=True)\n",
    "param0['regressor__l1_ratio'] = np.arange(0.0, 1.0, 0.1)\n",
    "param0['regressor'] = [reg0]\n",
    "\n",
    "param1 = {}\n",
    "param1['regressor__n_estimators'] = [50, 100, 250]\n",
    "param1['regressor__max_depth'] = [3, 6, 10]\n",
    "param1['regressor__learning_rate'] = [0.01, 0.05, 0.1]\n",
    "param1['regressor__colsample_bytree']: [0.3, 0.7]\n",
    "param1['regressor'] = [reg1]\n",
    "\n",
    "param2 = {}\n",
    "param2['regressor__kernel'] = [\"rbf\"]\n",
    "param2['regressor__C'] = [0.1, 1, 10, 100, 1000]\n",
    "param2['regressor'] = [reg2]\n",
    "\n",
    "param3 = {}\n",
    "param3['regressor__max_depth'] = [3,4,5]\n",
    "param3['regressor__n_estimators'] = [100, 200, 300]\n",
    "param3['regressor__learning_rate'] = [0.01, 0.05, 0.1]\n",
    "param3['regressor'] = [reg3]\n",
    "\n",
    "# param4 = {}\n",
    "# param4['regressor__n_estimators'] = [100,200,500]\n",
    "# param4['regressor__learning_rate'] = [.001,0.01,.1]\n",
    "# param4['regressor__max_depth'] = [1,2,4]\n",
    "# param4['regressor'] = [reg4]\n",
    "\n",
    "param5 = {}\n",
    "param5['regressor__num_leaves'] = [200,300,500, 800]\n",
    "param5['regressor__learning_rate'] = [.001,0.01,.1, 0.05]\n",
    "param5['regressor__feature_fraction'] = [0.3,0.6,0.9, 1]\n",
    "param5['regressor__bagging_freq'] = [30, 50,70,90, 100]\n",
    "param5['regressor'] = [reg5]\n",
    "\n",
    "params = [param1, param2, param3, param5]\n",
    "\n",
    "def tune(reg, param):\n",
    "    pipeline = Pipeline([('regressor', reg)])\n",
    "    rs = RandomizedSearchCV(pipeline, param, cv=5, scoring='neg_mean_squared_error')\n",
    "    rs.fit(X_train, y_train)\n",
    "    return rs.best_params_, rs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune(reg0, param0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune(reg1, param1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune(reg2, param2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune(reg3, param3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune(reg5, param5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
